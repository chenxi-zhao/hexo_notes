## 缓存在大型网站架构中的应用


### 缓存的基本知识
在整个计算机体系构造中（无论是硬件层面还是软件层面），缓存都是无处不在的。
在计算机硬件构造中，由于两种介质的速度不匹配，高速介质在和低速介质交互时速度趋向低速方，这就导致了高速介质的资源闲置。而通过引入第三种介质（速度和成本介于两者中间），将低速方读写的部分内容数据保存在该介质中，高速方大多数情况下则无需和低速方直接交互，这样就能整体提升了交互的性能。这就是计算机体系中缓存的由来。比较典型的就是CPU缓存（CPU寄存器=>L1 cahce =>L2 cache =>内存=>硬盘），如图：
![](http://static.tmaczhao.cn/images/f7e84a9acae6c6a8437d7ba5935d9c1f.jpg)

在计算机系统和应用软件层面，缓存更是无处不在。我们在使用浏览器上网时，很多静态资源会被缓存到本地。我们在手机上采用微信聊天时，很多好友的头像等数据会被缓存到手机中。在操作系统层面，I/O操作也会被内核缓存（一般将数据缓存在文件系统的缓存页中），当然，这个可能相比前两个场景更加抽象，但缓存的目的都是一致的，为了提升读写性能。

>缓存在狭义上解决介质读写速度不匹配问题，广义上包括任何利用中间媒介提高速度的方法，包括：空间换时间，动态操作变为静态操作

#### 缓存（CACHE）和缓冲（BUFFER）
缓存：可以共享，多种数据，大小不固定，可以重复使用，已知数据，用于提高IO效率。

缓冲：不可以共享，单一数据，大小固定，读取后失效，命中100%，未知数据，用于减少IO次数。


#### 缓存的属性
- 命中率：从缓存中返回正确数据的次数/总请求次数。
- 容量：超过这个值启用一定的策略：转移到磁盘；转移到远端；清空部分。
- 存储介质：内存、磁盘。
- 成本：开发成本、部署成本、硬件成本。
- 效率：SET效率、GET效率、序列化、哈希算法、分布式算法。

#### 缓存的限制
由于价格的因素，缓存实现依赖的存储往往有大小限制——保存什么，舍弃什么，命中率。缓存往往是从无到有的——在最初阶段不能发挥作用，在不命中的时候性能颠簸。


#### 缓存的分类
1. 按照存储介质来分 ：
- 内存（网站进程内、同服务器独立进程、独立服务器、分布式服务器组）。
- 磁盘（本地文件和数据库，独立服务器、分布式服务器组）。

缓存可以使用磁盘而不仅仅是内存。

2. 按照存储的数据来分 ：
- 直接用于输出的整页（HTML、脚本样式、图片）。
- 片段页（可供多个客户端使用的HTML、脚本样式等）。
- 索引和聚合数据（空间换时间）。
- 耗时查询的结果数据。
- 和业务相关的大块数据（列表数据，引用数据）。
- 和业务相关的小级数据（行级数据，资源数据）。
- 和上下文（用户）相关的数据（活动数据）。

3. 按照实现方式来分 ：
- 框架或引擎内置的缓存（比如ORM缓存和SQL SERVER缓存）。
- 安装特定的组件根据规则自动实现缓存（比如反向代理和输出缓存）。
- 需要由开发以编程方式实现的缓存（比如业务数据缓存）。

4. 按照作用来分 ：
- 用于数据的读取（之后介绍的大部分内容都是基于此类缓存）
- 用于（允许丢失）数据的写入——写到缓存的队列中，再由工作线程提交处理（写入存储）

#### 网站架构中的缓存
- 浏览器缓存（HTTP缓存头）
- 代理缓存（Squid Vanish CDN）
- Web服务器缓存（内核缓存、应用缓存）
- 页面输出缓存（片段缓存、整页缓存）
- 业务数据缓存（本地缓存，分布式缓存）
- 其它缓存（ORM、数据库、搜索引擎等缓存）


#### 缓存的常见模式和策略（过期、更新、清除）
![](http://static.tmaczhao.cn/images/05912978d0d52af5f747c845fb9b87cd.jpg)

##### 缓存的策略：
- 被动更新
在获取数据的时候，如果缓存中没有（可能缓存已经过期了），则尝试去数据库中获取，最后将最新的数据再写入到缓存中。

- 主动更新
更新数据的时候，主动更新缓存（直接将数据写入到缓存中）。

- 定时更新
通过独立的线程或者任务调度，定时将缓存数据进行更新。

- 通知更新
可以通过MQ等方式来通知缓存更新，这其实也是一种主动更新的策略，一定程度可以解耦。

- 不更新
对于有些不可能发生改变的数据，可以永久缓存起来。

##### 缓存的过期（失效）策略：
- 绝对的过期时间
这种是最常见的方式。当到达指定时间后，缓存将自动失效。

- 平滑过期
类似session的超时机制，实际使用较少。

- 依赖方式
在.NET平台内置的本地缓存中，支持依赖数据库或文件来更新缓存，但实际开发中很少用。

- 永远不过期
对于有些不可能发生改变的数据，可以永久缓存起来。

##### 缓存的清除（替换）策略：
- RAND，删除随机数据，不能反映局部性。
- SIZE，删除最大的数据。
- FIFO，First In First Out 删除最先进入缓存的数据，不能反映局部性。
- LFU，Least Frequently Used 删除一直以来最少被使用的数据。
- LRU，Least Recently Used 删除最近最少使用的数据。

其中，LUR算法是最被广泛使用的。



### 如何提高缓存命中率
#### 缓存命中率的介绍
- 命中：可以直接通过缓存获取到需要的数据。
- 不命中：无法直接通过缓存获取到想要的数据，需要再次查询数据库或者执行其它的操作。原因可能是由于缓存中根本不存在，或者缓存已经过期。

通常来讲，缓存的命中率越高则表示使用缓存的收益越高，应用的性能越好（响应时间越短、吞吐量越高），抗并发的能力越强。
由此可见，在高并发的互联网系统中，缓存的命中率是至关重要的指标。

#### 如何监控缓存的命中率
1. 在memcached中，运行state命令可以查看memcached服务的状态信息，其中cmd_get表示总的get次数，get_hits表示get的总命中次数，命中率=get_hits/cmd_get。
当然，我们也可以通过一些开源的第三方工具对整个memcached集群进行监控，显示会更直观。比较典型的包括：zabbix、MemAdmin等。


2. 同理，在redis中可以运行info命令查看redis服务的状态信息，其中keyspace_hits为总的命中中次数，keyspace_misses为总的miss次数，命中率=keyspace_hits/（keyspace_hits+keyspace_misses）。
开源工具Redis-star能以图表方式直观redis服务相关信息，同时，zabbix也提供了相关的插件对redis服务进行监控。


#### 影响缓存命中率的几个因素。
- 业务场景和业务需求
缓存适合“读多写少”的业务场景，反之，使用缓存的意义其实并不大，命中率会很低。
业务需求决定了对时效性的要求，直接影响到缓存的过期时间和更新策略。时效性要求越低，就越适合缓存。在相同key和相同请求数的情况下，缓存时间越长，命中率会越高。**互联网应用的大多数业务场景下都是很适合使用缓存的。**

- 缓存的设计（粒度和策略）
通常情况下，缓存的粒度越小，命中率会越高。举个实际的例子说明：
当缓存单个对象的时候（例如：单个用户信息），只有当该对象对应的数据发生变化时，我们才需要更新缓存或者让移除缓存。而当缓存一个集合的时候（例如：所有用户数据），其中任何一个对象对应的数据发生变化时，都需要更新或移除缓存。

还有另一种情况，假设其他地方也需要获取该对象对应的数据时（比如其他地方也需要获取单个用户信息），如果缓存的是单个对象，则可以直接命中缓存，反之，则无法直接命中。这样更加灵活，缓存命中率会更高。

此外，缓存的更新/过期策略也直接影响到缓存的命中率。当数据发生变化时，直接更新缓存的值会比移除缓存（或者让缓存过期）的命中率更高，当然，系统复杂度也会更高。

- 缓存容量和基础设施
缓存的容量有限，则容易引起缓存失效和被淘汰（目前多数的缓存框架或中间件都采用了LRU算法）。同时，缓存的技术选型也是至关重要的，比如采用应用内置的本地缓存就比较容易出现单机瓶颈，而采用分布式缓存则毕竟容易扩展。所以需要做好系统容量规划，并考虑是否可扩展。此外，不同的缓存框架或中间件，其效率和稳定性也是存在差异的。

- 其他因素
当缓存节点发生故障时，需要避免缓存失效并最大程度降低影响，这种特殊情况也是架构师需要考虑的。业内比较典型的做法就是通过一致性Hash算法，或者通过节点冗余的方式。

有些朋友可能会有这样的理解误区：既然业务需求对数据时效性要求很高，而缓存时间又会影响到缓存命中率，那么系统就别使用缓存了。其实这忽略了一个重要因素--并发。通常来讲，在相同缓存时间和key的情况下，并发越高，缓存的收益会越高，即便缓存时间很短。


#### 提高缓存命中率的方法
从架构师的角度，需要应用尽可能的通过缓存直接获取数据，并避免缓存失效。这也是比较考验架构师能力的，需要在业务需求，缓存粒度，缓存策略，技术选型等各个方面去通盘考虑并做权衡。尽可能的聚焦在**`高频访问且时效性要求不高`**的热点业务上，通过缓存预加载（预热）、增加存储容量、调整缓存粒度、更新缓存等手段来提高命中率。

对于时效性很高（或缓存空间有限），内容跨度很大（或访问很随机），并且访问量不高的应用来说缓存命中率可能长期很低，可能预热后的缓存还没来得被访问就已经过期了。



### 缓存在高并发场景下的常见问题
#### 缓存一致性问题
当数据时效性要求很高时，需要保证缓存中的数据与数据库中的保持一致，而且需要保证缓存节点和副本中的数据也保持一致，不能出现差异现象。这就比较依赖缓存的过期和更新策略。一般会在数据发生更改的时，主动更新缓存中的数据或者移除对应的缓存。
![](http://static.tmaczhao.cn/images/a30dfd4191cd274f47307c32c3150063.jpg)

#### 缓存并发问题
缓存过期后将尝试从后端数据库获取数据，这是一个看似合理的流程。但是，在高并发场景下，有可能多个请求并发的去从数据库获取数据，对后端数据库造成极大的冲击，甚至导致 “雪崩”现象。此外，当某个缓存key在被更新时，同时也可能被大量请求在获取，这也会导致一致性的问题。那如何避免类似问题呢？我们会想到类似“锁”的机制，在缓存更新或者过期的情况下，先尝试获取到锁，当更新或者从数据库获取完成后再释放锁，其他的请求只需要牺牲一定的等待时间，即可直接从缓存中继续获取数据。
![](http://static.tmaczhao.cn/images/6acc23fb39bfc3f07aed2f5782b87ed4.jpg)

#### 缓存穿透问题
缓存穿透在有些地方也称为“击穿”。很多朋友对缓存穿透的理解是：由于缓存故障或者缓存过期导致大量请求穿透到后端数据库服务器，从而对数据库造成巨大冲击。这其实是一种误解。真正的缓存穿透应该是这样的：
>在高并发场景下，如果某一个key被高并发访问，没有被命中，出于对容错性考虑，会尝试去从后端数据库中获取，从而导致了大量请求达到数据库，而当该key对应的数据本身就是空的情况下，这就导致数据库中并发的去执行了很多不必要的查询操作，从而导致巨大冲击和压力。

可以通过下面的几种常用方式来避免缓存传统问题：
- 缓存空对象
对查询结果为空的对象也进行缓存，如果是集合，可以缓存一个空的集合（非null），如果是缓存单个对象，可以通过字段标识来区分。这样避免请求穿透到后端数据库。同时，也需要保证缓存数据的时效性。这种方式实现起来成本较低，比较适合命中不高，但可能被频繁更新的数据。

- 单独过滤处理
对所有可能对应数据为空的key进行统一的存放，并在请求前做拦截，这样避免请求穿透到后端数据库。这种方式实现起来相对复杂，比较适合命中不高，但是更新不频繁的数据。

#### 缓存颠簸问题
缓存的颠簸问题，有些地方可能被成为“缓存抖动”，可以看做是一种比“雪崩”更轻微的故障，但是也会在一段时间内对系统造成冲击和性能影响。一般是由于缓存节点故障导致。业内推荐的做法是通过一致性Hash算法来解决。这里不做过多阐述，可以参照其他章节。

#### 缓存的雪崩现象
缓存雪崩就是指由于缓存的原因，导致大量请求到达后端数据库，从而导致数据库崩溃，整个系统崩溃，发生灾难。导致这种现象的原因有很多种，上面提到的“缓存并发”，“缓存穿透”，“缓存颠簸”等问题，其实都可能会导致缓存雪崩现象发生。这些问题也可能会被恶意攻击者所利用。还有一种情况，例如某个时间点内，系统预加载的缓存周期性集中失效了，也可能会导致雪崩。为了避免这种周期性失效，可以通过设置不同的过期时间，来错开缓存过期，从而避免缓存集中失效。

从应用架构角度，我们可以通过限流、降级、熔断等手段来降低影响，也可以通过多级缓存来避免这种灾难。

此外，从整个研发体系流程的角度，应该加强压力测试，尽量模拟真实场景，尽早的暴露问题从而防范。

#### 缓存无底洞现象
该问题由 facebook 的工作人员提出的， facebook 在 2010 年左右，memcached 节点就已经达3000 个，缓存数千G内容。
他们发现了一个问题---memcached连接频率，效率下降了，于是加memcached节点，添加了后，发现因为连接频率导致的问题，仍然存在，并没有好转，称之为”无底洞现象”。
![](http://static.tmaczhao.cn/images/c122c8e3cad1eee351e8050791d39e86.jpg)

目前主流的数据库、缓存、Nosql、搜索中间件等技术栈中，都支持“分片”技术，来满足“高性能、高并发、高可用、可扩展”等要求。有些是在client端通过Hash取模（或一致性Hash）将值映射到不同的实例上，有些是在client端通过范围取值的方式映射的。当然，也有些是在服务端进行的。但是，每一次操作都可能需要和不同节点进行网络通信来完成，实例节点越多，则开销会越大，对性能影响就越大。

主要可以从如下几个方面避免和优化：
- 数据分布方式
有些业务数据可能适合Hash分布，而有些业务适合采用范围分布，这样能够从一定程度避免网络IO的开销。

- IO优化
可以充分利用连接池，NIO等技术来尽可能降低连接开销，增强并发连接能力。

- 数据访问方式
一次性获取大的数据集，会比分多次去获取小数据集的网络IO开销更小。

当然，缓存无底洞现象并不常见。在绝大多数的公司里可能根本不会遇到。


