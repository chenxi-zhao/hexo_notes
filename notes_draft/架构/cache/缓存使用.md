缓存，是互联网分层架构中，非常重要的一个部分，通常用它来 **降低数据库压力，提升系统整体性能，缩短访问时间**。

>缓存分为进程内缓存，缓存集群(redis/memcached)

### 进程内缓存
进程内缓存的实现载体主要是一个带锁的Map，或者使用第三方库，比如guava

进程内缓存主要好处是：不用直接访问数据库，节省网络带宽以及网络延迟。但是进程内缓存在多台机器上存储了多份数据，很难保证其一致性。

那么则么保证进程内缓存一致性呢?
1. 单节点通知其他节点，写请求发生在A，修改完数据后主动通知其他节点修改数据。缺点是多节点耦合关系比较复杂。
2. 通过MQ通知其他节点。前两种方案，节点数量越多，数据冗余越多，原子性很难保证，一致性也就很难保证
3. 放弃实时一致性，通过固定时间拉取最新数据，这样容易读到脏数据，并且增加服务器压力

所以进程内缓存在系统不应当被频繁使用，因为进程内缓存可能导致多节点数据不一致，如果业务依赖于这部分缓存将影响系统的无状态性，不利于系统的水平扩展。

那么在那些情况下我们可以使用进程内缓存呢？
1. 只读数据
2. 高并发透传后端压力太大
3. 对于数据一致性要求不是很高的业务场景，比如一些运营，计数之类的。


### 怎么选择redis和memcached
#### 倾向于redis
1. 需要存储的数据结构复杂，如hash，列表，集合等，比如存储消息列表，评论列表等
2. 需要持久化，当然redis的持久化做的也不是很好（AOF影响性能，瞬时快照可能会丢数据）
3. 缓存固化。如果挂了可以快速恢复热数据，不会把压力瞬时打到库上导致挂库。但是
4. 高可用。需要考虑的是我们是否需要高可用
5. 存储内容太大，memcached最大value只支持1M

#### memcache
纯KV，数据量非常大，并发量非常大的业务，使用memcache或许更适合。

1. 内存分配
    - memcache使用预分配内存池的方式管理内存，能够省去内存分配时间。
    - redis则是临时申请空间，可能导致碎片。

2. 虚拟内存使用
    - memcache把所有的数据存储在物理内存里。
    - redis有自己的VM机制，理论上能够存储比物理内存更多的数据，当数据超量时，会引发swap，把冷数据刷到磁盘上。

3. 网络模型
    - memcache使用非阻塞IO复用模型，redis也是使用非阻塞IO复用模型。
    - 但由于redis还提供一些非KV存储之外的排序，聚合功能，在执行这些功能时，复杂的CPU计算，会阻塞整个IO调度。

4. 线程模型
    - memcache使用多线程，主线程监听，worker子线程接受请求，执行读写，这个过程中，可能存在锁冲突。
    - redis使用单线程，虽无锁冲突，但难以利用多核的特性提升整体吞吐量。


### 缓存使用tip
 - 服务与服务之间不要通过缓存传递数据，使用MQ比缓存解耦
 - 如果缓存挂掉，可能导致雪崩，此时要做高可用缓存，或者水平切分(分片)
 - 调用方不宜再单独使用缓存存储服务底层的数据，容易出现数据不一致，以及反向依赖
 - 不同服务，缓存实例要做垂直拆分（防止key冲突，吞吐量问题，服务耦合）



### 淘汰缓存还是修改缓存
允许cache miss的场景，不管是memcache还是redis，当被缓存的内容变化时，是改修改缓存，还是淘汰缓存？

#### KV缓存中存储的数据
1. 简单类型，int，String等
2. 序列化对象，本质是二进制流
3. 文本数据，json，xml，html等
...

#### 淘汰或者修改缓存中的这些数据，有什么差别
 - 淘汰某个key，操作简单，直接将key置为无效，但下一次该key的访问会cache miss
 - 修改某个key的内容，逻辑相对复杂，但下一次该key的访问仍会cache hit

#### 缓存中的value数据一般是怎么修改的？
 - 朴素类型的数据，直接set修改后的值即可
 - 序列化后的对象：一般需要先get数据，反序列化成对象，修改其中的成员，再序列化为binary，再set数据
 - json或者html数据：一般也需要先get文本，parse成doom树对象，修改相关元素，序列化为文本，再set数据

>对于对象类型，或者文本类型，修改缓存value的成本较高，一般选择直接淘汰缓存。

#### 总结
是否需要淘汰缓存主要就是看如果修改数据对于系统的操作成本高不高


### 先操作数据库还是先操作缓存
>不管先操作数据库，还是先操作缓存，都解决不了“写后立刻读，脏数据库入缓存”的问题。

#### 先缓存，后库
先delete缓存，后操作数据库可以解决单线程环境内，不会因为缓存操作或者数据库操作失败引起数据不一致。
但是这样在并发环境下删除完缓存，未更新数据库时，可能存在第二个线程读取缓存失败回源数据库为老数据导致数据不一致

#### 先库，后缓存
可以解决读写并发时读取到脏数据问题，但是可能出现缓存操作失败导致数据不一致情况


### 数据库主从不一致，怎么解？
1. 忽略。业务允许情况下最好的方法，系统架构保持简单更加能够抗高负载
2. 强制性读主库，使用一个高可用主库提供数据库服务，用缓存提升读性能
3. 选择性读主。通过缓存记录被修改过的数据，根据策略选择读主还是读从（比如2s内更新过读主，2s后就读从）


### 关于Cache的问题/陷阱
1. 多级Cache支持
    - 应用开发时往往会考虑加上内存Cache，因为内存Cache性能高很多于Cache中间件（如Memcached）
        - 当然要特别注意的是 内存Cache数据条目上限 的设置，避免内存消耗过多导致应用瘫痪。
        - 由于内存中Cache数据条目，如何决定哪些数据要Cache，移出策略的设置变得要好好思考。
        - 如果Cache涉及数据条目很多、很分散没有时间局部性，那么内存Cache可能是浪费内存且增加了操作性能更低。
    - 这样数据访问路径就成了：内存Cache -> 远程Cache -> 实际数据（如DB）

2. 无实际数据时的防击穿
    导致没有数据时，一直会访问DB。

3. Cache中没有数据时，即首次加载时，并发的Cache请求的防击穿
    期望在这种情况下，并发请求只会触发一次实际数据请求，数据请求完成后，所有并发Cache请求都返回数据。

4. 使用Cache请求时，透明数据的加载，即
    - 业务实现不需要自己写这样的逻辑：
        - 如果Cache中没有数据读实际数据，设置好Cache；
        - 如果Cache中有数据返回Cache数据。
        - 这样逻辑繁琐易漏易错。
    - Cache会持有加载实际数据的Loader，参见Guava的CacheLoader模式。

如果有『击穿』的情况，系统性能压力上来时会雪崩，而你想依赖的之前性能压测的性能数据已经没有意义了。